{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0+nmoe+xEB+uynxt5CP/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asil07/daily-coding-challenge/blob/main/Machine_Learning_Model_Development_for_Data_Processing_and_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ8ODYflwjVt",
        "outputId": "e82a6924-f865-4e30-eb74-03de8e91a737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 134508.7715345625\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from river import tree, metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('oca-competitor-gas-fee-data-2.csv')\n",
        "\n",
        "# Encode 'sender' column into numerical values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['sender_encoded'] = label_encoder.fit_transform(df['sender'])\n",
        "\n",
        "# Define features and target\n",
        "X = df[['blockNumber', 'sender_encoded']]\n",
        "y = df['max']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Hoeffding Tree Regressor\n",
        "model = tree.HoeffdingTreeRegressor()\n",
        "\n",
        "# Define a metric to evaluate the model\n",
        "metric = metrics.MAE()\n",
        "\n",
        "# Incremental training with Hoeffding Tree\n",
        "for i in range(len(X_train_scaled)):\n",
        "    model.learn_one(dict(enumerate(X_train_scaled[i])), y_train.iloc[i])\n",
        "\n",
        "# Evaluate the model on test data\n",
        "y_pred_test = []\n",
        "for i in range(len(X_test_scaled)):\n",
        "    y_pred = model.predict_one(dict(enumerate(X_test_scaled[i])))\n",
        "    y_pred_test.append(y_pred)\n",
        "    metric.update(y_test.iloc[i], y_pred)\n",
        "\n",
        "# Print the MAE metric\n",
        "print(f\"Mean Absolute Error (MAE): {metric.get()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip  install river"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G05jFCYywtXv",
        "outputId": "7da3c3c2-472b-42fa-f348-2314d2884b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting river\n",
            "  Downloading river-0.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from river) (1.26.4)\n",
            "Requirement already satisfied: pandas<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from river) (2.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from river) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=2.1->river) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=2.1->river) (1.16.0)\n",
            "Downloading river-0.21.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: river\n",
            "Successfully installed river-0.21.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6658lgKywx-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from river import tree\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from river import metrics\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('oca-competitor-gas-fee-data-2.csv')\n",
        "\n",
        "# Encode 'sender' column into numerical values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['sender_encoded'] = label_encoder.fit_transform(df['sender'])\n",
        "\n",
        "# Define features and target\n",
        "X = df[['blockNumber', 'sender_encoded']]\n",
        "y = df['max']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize models\n",
        "hoeffding_tree = tree.HoeffdingTreeRegressor()\n",
        "sgd_model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
        "\n",
        "# Initialize a metric for the ensemble\n",
        "ensemble_metric = metrics.MAE()\n",
        "\n",
        "# Train models and collect predictions for ensemble\n",
        "sgd_predictions = []\n",
        "hoeffding_predictions = []\n",
        "ensemble_predictions = []\n",
        "\n",
        "# Train Hoeffding Tree Regressor and SGD Regressor incrementally\n",
        "for i in range(len(X_train_scaled)):\n",
        "    # Update Hoeffding Tree\n",
        "    hoeffding_tree.learn_one(dict(enumerate(X_train_scaled[i])), y_train.iloc[i])\n",
        "\n",
        "    # Update SGD Regressor\n",
        "    sgd_model.partial_fit([X_train_scaled[i]], [y_train.iloc[i]])\n",
        "\n",
        "# Make predictions for the test set and combine them\n",
        "for i in range(len(X_test_scaled)):\n",
        "    # Get predictions from each model\n",
        "    ht_pred = hoeffding_tree.predict_one(dict(enumerate(X_test_scaled[i])))\n",
        "    sgd_pred = sgd_model.predict([X_test_scaled[i]])[0]\n",
        "\n",
        "    # Average the predictions for ensemble\n",
        "    ensemble_pred = (ht_pred + sgd_pred) / 2\n",
        "    ensemble_predictions.append(ensemble_pred)\n",
        "\n",
        "    # Update the ensemble metric\n",
        "    ensemble_metric = ensemble_metric.update(y_test.iloc[i], ensemble_pred)\n",
        "\n",
        "# Print the final MAE for the ensemble\n",
        "print(f\"Ensemble Mean Absolute Error (MAE): {ensemble_metric.get()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "wJuv7MWnxqfe",
        "outputId": "1c0a88a0-9745-41d3-92f4-efd7e991215e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'update'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2b7301def079>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Update the ensemble metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mensemble_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Print the final MAE for the ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update'"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "from river import tree\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from river import metrics\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('oca-competitor-gas-fee-data-2.csv')\n",
        "\n",
        "# Encode 'sender' column into numerical values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['sender_encoded'] = label_encoder.fit_transform(df['sender'])\n",
        "\n",
        "# Define features and target\n",
        "X = df[['blockNumber', 'sender_encoded']]\n",
        "y = df['max']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize models\n",
        "hoeffding_tree = tree.HoeffdingTreeRegressor()\n",
        "sgd_model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
        "\n",
        "# Initialize a metric for the ensemble\n",
        "ensemble_metric = metrics.MAE()\n",
        "\n",
        "# Train models and collect predictions for ensemble\n",
        "sgd_predictions = []\n",
        "hoeffding_predictions = []\n",
        "ensemble_predictions = []\n",
        "\n",
        "# Train Hoeffding Tree Regressor and SGD Regressor incrementally\n",
        "for i in range(len(X_train_scaled)):\n",
        "    # Update Hoeffding Tree\n",
        "    hoeffding_tree.learn_one(dict(enumerate(X_train_scaled[i])), y_train.iloc[i])\n",
        "\n",
        "    # Update SGD Regressor\n",
        "    sgd_model.partial_fit([X_train_scaled[i]], [y_train.iloc[i]])\n",
        "\n",
        "# Make predictions for the test set and combine them\n",
        "for i in range(len(X_test_scaled)):\n",
        "    # Get predictions from each model\n",
        "    ht_pred = hoeffding_tree.predict_one(dict(enumerate(X_test_scaled[i])))\n",
        "    sgd_pred = sgd_model.predict([X_test_scaled[i]])[0]\n",
        "\n",
        "    # Average the predictions for ensemble\n",
        "    ensemble_pred = (ht_pred + sgd_pred) / 2\n",
        "    ensemble_predictions.append(ensemble_pred)\n",
        "\n",
        "    # Update the ensemble metric - Removed the assignment here\n",
        "    ensemble_metric.update(y_test.iloc[i], ensemble_pred)\n",
        "\n",
        "# Print the final MAE for the ensemble\n",
        "print(f\"Ensemble Mean Absolute Error (MAE): {ensemble_metric.get()}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htrKldWuzARY",
        "outputId": "9dc4c27a-c06d-4c26-d73c-b82048f50617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Mean Absolute Error (MAE): 138836.80270073336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0v5JnhDxqik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbzgrx9mxqk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdxZt47Vxqph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}